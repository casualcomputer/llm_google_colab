# Setting Up Large Language Models on Google Colab and Kaggle

This repository provides detailed tutorials for setting up and running Large Language Models (LLMs) on Google Colab and Kaggle. Whether you have access to GPU acceleration or are limited to a CPU-only environment, these guides will help you get started with deploying and utilizing LLMs efficiently.

## Features

- **GPU Accelerated Setup**: Use Google Colab's free Tesla T4 GPUs to speed up your model's performance by X60 times (compared to CPU only session). Note that GPU availability is limited by usage quotas.
- **CPU Only Setup**: A detailed guide to setting up LLMs on a CPU-only environment, perfect for users without access to GPU resources.
- **Comprehensive Instructions**: Each tutorial includes step-by-step instructions, from setting up the environment to executing the model.
- **Code Examples**: Includes complete, runnable Jupyter notebooks that you can directly import into Colab and start using.

## Tutorials

1. **[GPU Accelerated Setup](https://github.com/casualcomputer/llm_google_colab/blob/main/setup_llm_on_google_colab_gpu_accelerated.ipynb)**: This notebook walks you through the process of setting up a LLM on Google Colab with GPU acceleration. It includes instructions for optimizing your model to take full advantage of Google's hardware.

2. **[CPU Only Setup](https://github.com/casualcomputer/llm_google_colab/blob/main/setup_llm_on_google_colab_cpu_only.ipynb)**: For users without access to GPU resources, this notebook provides a detailed guide to setting up and running LLMs using only CPUs. It includes performance tips and best practices for maximizing efficiency.

3. **[Setting Up LLM on Kaggle GPU](https://github.com/casualcomputer/llm_google_colab/blob/main/setup-llm-on-kaggle-gpu.ipynb)**: This notebook guides you through the process of setting up a LLM on Kaggle using GPU acceleration. It includes steps to install necessary packages and optimize your model for Kaggle's hardware.

4. **[Running Ollama on Colab](https://github.com/casualcomputer/llm_google_colab/blob/main/setup_ollama_google_colab.ipynb)**: This notebook guides you through the process of running and serving LLaMA3 through Ollama. It allows learners to interact with LLM easily and experimenting different open-source LLM's.

5. **[Mimicking Data Analysts with Gemini/Ollama & CrewAI Agents](https://github.com/casualcomputer/llm_google_colab/blob/main/setup_crewai_agents_google_colab.ipynb)**: Explore this notebook to see how Gemini, orchestrated by CrewAI agents, can replicate the workflow of a data analyst. It focuses on rapidly uncovering insights and flagging data quality concerns in your datasets. Note, code snippets on leveraging Ollama is coming.

## Getting Started

To get started with these tutorials, follow these steps:

- Fork this repository or download the notebooks directly.
- Open Google Colab or Kaggle and upload the notebook corresponding to your preferred setup.
- Follow the instructions within the notebook to set up your LLM.

## Requirements

- A Google Colab or Kaggle account.
- Basic knowledge of Python programming and Jupyter notebooks.

## Contributing

Contributions are welcome! If you have improvements or additions to the tutorials, please fork the repository and submit a pull request.

## License

This project is licensed under the GPL-3.0 license - see the [LICENSE](https://github.com/casualcomputer/llm_google_colab/blob/main/LICENSE) file for details.

## Acknowledgements

Thanks to the open-source community, Google Colab, and Kaggle for providing the resources that make these tutorials possible.
